from pathlib import Path
import os
from llm_judge_helper import load_lines_from_file, evaluate_transcript_batch

"""
run_llm_jargon.py

Evaluates how an LLM judges reference text with STT text generated by whisper-base.en
Here, I'll be using gpt-4o-mini. See llm_judge_helper.py for more info
"""

# Access the current (src/wer) and parent (src/) directory via Pathlib
curr_dir = Path(__file__).resolve().parent
parent_dir = curr_dir.parent

# Access the transcript paths
ref_path = parent_dir / "transcripts/reference_transcripts.txt"
whisper_jargon_path = parent_dir / "transcripts/whisper_jargon_transcripts.txt"

# Then, load the transcripts line-by-line
ref_transcripts = load_lines_from_file(ref_path)
whisper_jargon_transcripts = load_lines_from_file(whisper_jargon_path)

# Write output files for all three models that we'll run
whisper_jargon_output_folder = curr_dir / "jargon" / "whisper_jargon"

# Run the evaluation tests for the files
evaluate_transcript_batch(ref_transcripts, whisper_jargon_transcripts, whisper_jargon_output_folder)
